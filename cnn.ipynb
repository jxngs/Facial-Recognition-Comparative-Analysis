{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from filereader import FileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "face_dataset = datasets.fetch_lfw_people(min_faces_per_person=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (100, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=47x62>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the first image in the image dataset\n",
    "first_image = face_dataset.images[0]\n",
    "img = keras.preprocessing.image.array_to_img(np.expand_dims(first_image * 255, axis=-1))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out images if they're the > 150th image for a class -- don't want too many of some classes\n",
    "# kept_images = []\n",
    "# kept_labels = []\n",
    "# frequencies = {}\n",
    "\n",
    "# for image, label in zip(face_dataset.images, face_dataset.target):\n",
    "#     if label not in frequencies:\n",
    "#         frequencies[label] = 0\n",
    "#     if frequencies[label] > 150:\n",
    "#         continue\n",
    "#     kept_images.append(image)\n",
    "#     kept_labels.append(label)\n",
    "#     frequencies[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_labels, kept_images = FileReader.readFilesToVectors('./lfw-deepfunneled', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "frequencies = {name: kept_labels.count(name) for name in kept_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_images = np.array([np.resize(img, (IMAGE_SIZE, IMAGE_SIZE)) for img in kept_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap labels from [0, N - 1]\n",
    "\n",
    "old_labels_to_new_labels = {}\n",
    "for label in kept_labels:\n",
    "    if label not in old_labels_to_new_labels:\n",
    "        old_labels_to_new_labels[label] = len(old_labels_to_new_labels)\n",
    "\n",
    "kept_labels = [old_labels_to_new_labels[label] for label in kept_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.expand_dims(np.asarray(kept_images), axis=-1) # necessary to show there is 1 channel (grayscale)?\n",
    "labels = keras.utils.to_categorical(np.asarray(kept_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = datagen.flow(train_images, train_labels, batch_size=64, shuffle=True)\n",
    "val_data_generator = datagen.flow(val_images, val_labels, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# display first image in val data batch and its label -- just for validation\n",
    "first_batch = next(val_data_generator)\n",
    "display(keras.preprocessing.image.array_to_img(first_batch[0][0] * 255))\n",
    "print(first_batch[1][0])\n",
    "\n",
    "val_data_generator = datagen.flow(val_images, val_labels, batch_size=64, shuffle=True) # reset val_data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xception model from https://keras.io/examples/vision/image_classification_from_scratch/#using-image-data-augmentation\n",
    "\n",
    "# def make_model(input_shape, num_classes):\n",
    "#     inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "#     # Entry block\n",
    "#     x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "#     x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "#     previous_block_activation = x  # Set aside residual\n",
    "\n",
    "#     for size in [256, 512, 728]:\n",
    "#         x = layers.Activation(\"relu\")(x)\n",
    "#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "\n",
    "#         x = layers.Activation(\"relu\")(x)\n",
    "#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "\n",
    "#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "#         # Project residual\n",
    "#         residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "#             previous_block_activation\n",
    "#         )\n",
    "#         x = layers.add([x, residual])  # Add back residual\n",
    "#         previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "#     x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "#     if num_classes == 2:\n",
    "#         activation = \"sigmoid\"\n",
    "#         units = 1\n",
    "#     else:\n",
    "#         activation = \"softmax\"\n",
    "#         units = num_classes\n",
    "\n",
    "#     x = layers.Dropout(0.5)(x)\n",
    "#     outputs = layers.Dense(units, activation=activation)(x)\n",
    "#     return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# model = make_model(input_shape=IMAGE_SIZE + (1, ), num_classes=len(frequencies))\n",
    "\n",
    "input_shape = IMAGE_SIZE + (1, )\n",
    "num_classes = len(frequencies)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5749)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_data_generator)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "160/160 [==============================] - 211s 1s/step - loss: 14.4159 - accuracy: 0.0096 - val_loss: 8.4184 - val_accuracy: 0.0176\n",
      "Epoch 2/25\n",
      "160/160 [==============================] - 204s 1s/step - loss: 8.2932 - accuracy: 0.0126 - val_loss: 8.4671 - val_accuracy: 0.0196\n",
      "Epoch 3/25\n",
      "160/160 [==============================] - 196s 1s/step - loss: 8.1847 - accuracy: 0.0152 - val_loss: 8.4840 - val_accuracy: 0.0192\n",
      "Epoch 4/25\n",
      "160/160 [==============================] - 192s 1s/step - loss: 8.1137 - accuracy: 0.0149 - val_loss: 8.5220 - val_accuracy: 0.0176\n",
      "Epoch 5/25\n",
      " 24/160 [===>..........................] - ETA: 2:34 - loss: 8.0743 - accuracy: 0.0143"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.legacy.Adam(1e-3), # legacy for m1 support\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_data_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_data_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
