{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from filereader import FileReader\n",
    "import yalefaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (100, 100) \n",
    "THRESHOLD = 0 # change to 50 for lfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for lfw\n",
    "# all_labels, all_images = FileReader.readFilesToVectors('./lfw-deepfunneled', 100, 150, 50)\n",
    "# frequencies = {}\n",
    "# frequencies = {name: all_labels.count(name) for name in all_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for yalefaces\n",
    "all_images, all_labels = yalefaces.yale_data(100)\n",
    "unique_values, counts = np.unique(all_labels, return_counts=True)\n",
    "frequencies = dict(zip(unique_values, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_images = []\n",
    "kept_labels = []\n",
    "\n",
    "for img, label in zip(all_images, all_labels):\n",
    "    if frequencies[label] > THRESHOLD:\n",
    "        kept_images.append(img)\n",
    "        kept_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_images = np.array([np.resize(img, IMAGE_SIZE) for img in kept_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = kept_images[0]\n",
    "img = keras.preprocessing.image.array_to_img(np.expand_dims(first_image * 255, axis=-1))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap labels from [0, N - 1]\n",
    "\n",
    "old_labels_to_new_labels = {}\n",
    "for label in kept_labels:\n",
    "    if label not in old_labels_to_new_labels:\n",
    "        old_labels_to_new_labels[label] = len(old_labels_to_new_labels)\n",
    "\n",
    "kept_labels = [old_labels_to_new_labels[label] for label in kept_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.expand_dims(np.asarray(kept_images), axis=-1) # necessary to show there is 1 channel (grayscale)?\n",
    "labels = keras.utils.to_categorical(np.asarray(kept_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = datagen.flow(train_images, train_labels, batch_size=64, shuffle=True)\n",
    "val_data_generator = datagen.flow(val_images, val_labels, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# display first image in val data batch and its label -- just for validation\n",
    "first_batch = next(val_data_generator)\n",
    "display(keras.preprocessing.image.array_to_img(first_batch[0][0] * 255))\n",
    "print(first_batch[1][0])\n",
    "\n",
    "val_data_generator = datagen.flow(val_images, val_labels, batch_size=64, shuffle=True) # reset val_data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xception model from https://keras.io/examples/vision/image_classification_from_scratch/#using-image-data-augmentation\n",
    "\n",
    "# def make_model(input_shape, num_classes):\n",
    "#     inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "#     # Entry block\n",
    "#     x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "#     x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "#     previous_block_activation = x  # Set aside residual\n",
    "\n",
    "#     for size in [256, 512, 728]:\n",
    "#         x = layers.Activation(\"relu\")(x)\n",
    "#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "\n",
    "#         x = layers.Activation(\"relu\")(x)\n",
    "#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "\n",
    "#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "#         # Project residual\n",
    "#         residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "#             previous_block_activation\n",
    "#         )\n",
    "#         x = layers.add([x, residual])  # Add back residual\n",
    "#         previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "#     x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "#     if num_classes == 2:\n",
    "#         activation = \"sigmoid\"\n",
    "#         units = 1\n",
    "#     else:\n",
    "#         activation = \"softmax\"\n",
    "#         units = num_classes\n",
    "\n",
    "#     x = layers.Dropout(0.5)(x)\n",
    "#     outputs = layers.Dense(units, activation=activation)(x)\n",
    "#     return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# model = make_model(input_shape=IMAGE_SIZE + (1, ), num_classes=len(frequencies))\n",
    "\n",
    "input_shape = IMAGE_SIZE + (1, )\n",
    "num_classes = len(set(kept_labels))\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 15)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_data_generator)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 493ms/step - loss: 217.8266 - accuracy: 0.0530 - val_loss: 172.8399 - val_accuracy: 0.0303\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 163.0739 - accuracy: 0.0682 - val_loss: 117.1093 - val_accuracy: 0.1212\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 294ms/step - loss: 60.5492 - accuracy: 0.1364 - val_loss: 24.4884 - val_accuracy: 0.2727\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 15.8167 - accuracy: 0.1894 - val_loss: 4.1709 - val_accuracy: 0.2121\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 3.4108 - accuracy: 0.2879 - val_loss: 2.3564 - val_accuracy: 0.3939\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 1.6192 - accuracy: 0.4621 - val_loss: 1.4457 - val_accuracy: 0.4848\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 1s 321ms/step - loss: 1.3822 - accuracy: 0.5227 - val_loss: 1.1764 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 1.3208 - accuracy: 0.5455 - val_loss: 0.9826 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 1.2371 - accuracy: 0.5985 - val_loss: 0.9070 - val_accuracy: 0.6970\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 1.1654 - accuracy: 0.6439 - val_loss: 0.8116 - val_accuracy: 0.7576\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 0.9916 - accuracy: 0.6742 - val_loss: 0.6404 - val_accuracy: 0.7879\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.6587 - accuracy: 0.8106 - val_loss: 0.4191 - val_accuracy: 0.8788\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.6224 - accuracy: 0.7879 - val_loss: 0.3832 - val_accuracy: 0.9091\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.3514 - accuracy: 0.9167 - val_loss: 0.2694 - val_accuracy: 0.8788\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 1s 323ms/step - loss: 0.4794 - accuracy: 0.8712 - val_loss: 0.3954 - val_accuracy: 0.8788\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.3708 - accuracy: 0.8864 - val_loss: 0.4929 - val_accuracy: 0.8485\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 1s 367ms/step - loss: 0.1446 - accuracy: 0.9621 - val_loss: 0.4754 - val_accuracy: 0.8182\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.2203 - accuracy: 0.9318 - val_loss: 0.4655 - val_accuracy: 0.8788\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.3047 - accuracy: 0.9242 - val_loss: 0.2657 - val_accuracy: 0.9394\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 1s 303ms/step - loss: 0.2514 - accuracy: 0.9318 - val_loss: 0.2817 - val_accuracy: 0.8788\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 1s 303ms/step - loss: 0.1136 - accuracy: 0.9621 - val_loss: 0.1455 - val_accuracy: 0.9697\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 0.1464 - accuracy: 0.9773 - val_loss: 0.2899 - val_accuracy: 0.9394\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 0.1580 - accuracy: 0.9242 - val_loss: 0.2969 - val_accuracy: 0.9091\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.1405 - accuracy: 0.9394 - val_loss: 0.1807 - val_accuracy: 0.8788\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0645 - accuracy: 0.9773 - val_loss: 0.3569 - val_accuracy: 0.9394\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.0891 - accuracy: 0.9773 - val_loss: 0.3670 - val_accuracy: 0.8788\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.1192 - accuracy: 0.9697 - val_loss: 0.1481 - val_accuracy: 0.9697\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0833 - accuracy: 0.9773 - val_loss: 0.3531 - val_accuracy: 0.9091\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 1s 301ms/step - loss: 0.0812 - accuracy: 0.9697 - val_loss: 0.1933 - val_accuracy: 0.9394\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 0.0990 - accuracy: 0.9697 - val_loss: 0.3683 - val_accuracy: 0.9091\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.1670 - accuracy: 0.9621 - val_loss: 0.1610 - val_accuracy: 0.9394\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.2185 - accuracy: 0.9091 - val_loss: 0.3897 - val_accuracy: 0.8485\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.1337 - accuracy: 0.9545 - val_loss: 0.3682 - val_accuracy: 0.8485\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.2821 - accuracy: 0.9091 - val_loss: 0.3333 - val_accuracy: 0.9091\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 1s 299ms/step - loss: 0.1673 - accuracy: 0.9545 - val_loss: 0.3585 - val_accuracy: 0.9394\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.1962 - accuracy: 0.9697 - val_loss: 0.2479 - val_accuracy: 0.9394\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 1s 352ms/step - loss: 0.1501 - accuracy: 0.9470 - val_loss: 0.4577 - val_accuracy: 0.9394\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 0.1301 - accuracy: 0.9697 - val_loss: 0.3665 - val_accuracy: 0.9394\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.0810 - accuracy: 0.9697 - val_loss: 0.3931 - val_accuracy: 0.9091\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.1267 - accuracy: 0.9697 - val_loss: 0.3267 - val_accuracy: 0.9394\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9697\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0375 - accuracy: 0.9924 - val_loss: 0.2728 - val_accuracy: 0.9394\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 0.0616 - accuracy: 0.9924 - val_loss: 0.1736 - val_accuracy: 0.9394\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.1723 - accuracy: 0.9545 - val_loss: 0.2226 - val_accuracy: 0.9697\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9394\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0350 - accuracy: 0.9773 - val_loss: 0.2332 - val_accuracy: 0.9394\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 1s 351ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.3590 - val_accuracy: 0.9394\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 1s 323ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9394\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9394\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 0.0189 - accuracy: 0.9924 - val_loss: 0.4932 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ed3d83ea50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.legacy.Adam(1e-3), # legacy for m1 support\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_data_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_data_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
