import numpy as np
from sklearn import datasets
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix
import keras
from tensorflow.keras import layers
import sys
from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QComboBox, QPushButton, QVBoxLayout,QLineEdit,QFormLayout
from heapq import *

class FacialRecognitionAlgorithm:
    def __init__(self, modelname, dataset):
        self.modelname = modelname
        self.dataset=dataset

    def train(self):
        pass

    def predict(self):
        pass

    def show_results(self):
        pass

class Eigenfaces(FacialRecognitionAlgorithm):

    class PrincipalComponentsAnalysis:
        def __init__(self, n_components):
            self.n_components = n_components
            self.mean = None
            self.components = None
            self.explained_variances = None

        def fit(self, X):
            self.mean = np.mean(X, axis=0)
            centered_data = X - self.mean
            covariance_matrix = np.cov(centered_data, rowvar=False)
            eigendata = np.linalg.eigh(covariance_matrix)
            eigenvalues = eigendata[0]
            eigenvectors = eigendata[1]
            sorted_indices = np.argsort(eigenvalues)[::-1]
            eigenvectors = eigenvectors[:, sorted_indices]
            self.components = eigenvectors[:, :self.n_components]
            total_variance = np.sum(eigenvalues)
            self.explained_variances = eigenvalues[sorted_indices][:self.n_components] / total_variance

        def transform(self, X):
            centered_data = X - self.mean
            projected_data = np.dot(centered_data, self.components)
            whitened_data = projected_data / np.sqrt(self.explained_variances)
            return whitened_data


    def __init__(self, modelname, dataset, num_features,c_value):
        self.n_components=num_features
        self.C=c_value
        super().__init__(modelname, dataset)
        
    def train(self):
        self.X_train = self.X_train.reshape((len(self.X_train), -1))
        self.X_test = self.X_test.reshape((len(self.X_test), -1))

        custom_pca = self.PrincipalComponentsAnalysis(n_components=self.n_components)
        custom_pca.fit(self.X_train)

        self.X_training_reduced = custom_pca.transform(self.X_train)
        self.X_test_reduced = custom_pca.transform(self.X_test)

    def predict(self):
        bestacc=0

        self.classifier = SVC(kernel='linear', C=self.C)
        self.classifier.fit(self.X_training_reduced, self.y_train)
        self.y_predicted = self.classifier.predict(self.X_test_reduced)
        self.accuracy = accuracy_score(self.y_actual, self.y_predicted)
        
    def show_results(self):
        print(self.accuracy)
        ConfusionMatrixDisplay.from_estimator(
            self.classifier, self.X_test_reduced, self.y_actual, xticks_rotation="vertical"
        )
        plt.tight_layout()
        plt.show()


class FisherFaces(FacialRecognitionAlgorithm):
    def __init__(self, modelname, dataset, num_features):
        super().__init__(modelname, dataset)
        
        self.num_features = min(num_features, min(dataset.images[0].shape))
        

    def normalize(self, matrix, mean_all):
        min_val = np.min(mean_all)
        max_val = np.max(mean_all)
        normalized_matrix = 255 * (matrix - min_val) / (max_val - min_val)
        return normalized_matrix

    def train(self):
        
        n = len(self.X_train)
        unique_labels = list(set(self.y_train))
        self.classes = unique_labels
        class_means = []

        for i in range(len(unique_labels)):
            label = unique_labels[i]
            matching_indexes = np.where(self.y_train == label)[0]
            class_samples = self.X_train[matching_indexes]  # each c
            class_mean = np.mean(class_samples, axis=0)
            class_means.append(class_mean)
            
        class_means = np.array(class_means)
        mean_all = np.mean(class_means, axis=0)

        X = np.array([image for image in self.X_train])

        Sw = np.zeros((self.num_features, self.num_features))  # within class
        Sb = np.zeros((self.num_features, self.num_features))  # between-class

        for i in range(len(unique_labels)):
            label = unique_labels[i]
            class_samples = X[self.y_train == label]  # each c

            for class_sample in class_samples:
                Sw += np.dot((class_sample - class_means[i]).T, (class_sample - class_means[i]))

            Sb += len(class_samples) * np.dot((class_means[i] - mean_all), (class_means[i] - mean_all).T)

        eigenvalues, eigenvectors = np.linalg.eig(np.dot(np.linalg.inv(Sw), (Sb)))
        sort = np.argsort(eigenvalues)[::-1]
        eigenvalues = eigenvalues[sort]
        eigenvectors = eigenvectors[:, sort]

        class_means = np.dot(class_means, eigenvectors)

        self.fisherfaces = eigenvectors
        self.mean_face = mean_all
        self.class_means = class_means
        self.basis = eigenvalues

    def convert_bin(self, filename):
        with open(filename, 'rb') as file:
            binary_data = file.read()
            image = Image.open(io.BytesIO(binary_data))
            resized_image = image.resize((self.num_features, self.num_features))
            return np.array(resized_image)

    def convert_jpeg(self, filename):
        image = Image.open(filename)
        resized_image = image.resize((self.num_features, self.num_features))

        pixel_data = list(resized_image.getdata())
        greyscale_data = [0 for x in range(self.num_features * self.num_features)]

        for i in range(len(pixel_data)):
            rgb = pixel_data[i]
            greyscale_data[i] = 0.299 * rgb[0] + 0.587 * rgb[1] + 0.114 * rgb[2]

        greyscale_data = np.asarray(greyscale_data)
        greyscale_mat = greyscale_data.reshape(self.num_features, self.num_features)

        return greyscale_mat

    def predict_with_fisher(self, ff, image):
        projection = np.dot(image, ff)

        base_filepath = './altered_images'
        class_means = []
        names = []
        for class_name in os.listdir(base_filepath):
            if class_name == 'proj' or class_name == 'class0.jpeg':
                continue
            filepath = base_filepath + '/' + class_name
            names.append(class_name)
            image = ImageOps.grayscale(Image.open(filepath))
            class_means.append(np.resize(np.array(image), (self.num_features, self.num_features)))

        distances = []
        for c in class_means:
            distances.append(np.linalg.norm(projection - np.resize(c, (self.num_features, self.num_features))))
        distances = np.array(distances)

        predicted_label = np.argmin(distances)
        distance = distances[predicted_label]
        smallest_indexes = sorted(range(len(distances)), key=lambda i: distances[i])[:100]

        return names[predicted_label], distance, np.array(names)[np.array(smallest_indexes)], np.array(distances)[
            np.array(smallest_indexes)]

    def predict(self):
        def predict1(image):
            projection = np.dot(image, self.fisherfaces)

            distances = []
            for c in self.class_means:
                distances.append(np.linalg.norm(projection - c))
            distances = np.array(distances)

            predicted_label = np.argmin(distances)

            distance = distances[predicted_label]
            return self.classes[predicted_label], distance
        self.accuracy = 0
        self.conf_matrix = np.zeros((len(self.dataset.labeldict), len(self.dataset.labeldict)))
        self.y_predicted=[]
        for x,y in zip(self.X_test, self.y_actual):
            
            pred = predict1(x)
            try:
                self.conf_matrix[self.dataset.reversedict[y], self.dataset.reversedict[pred[0]]] += 1
            except:
                self.conf_matrix[y, pred[0]] += 1
            self.y_predicted.append(pred[0])
            if y == pred[0]: self.accuracy += 1
        
        print('accuracy', self.accuracy/len(self.X_test))
        
    def show_results(self):
        conf_matrix = confusion_matrix(self.y_actual, np.asarray(self.y_predicted), labels=self.classes)
        
        plt.imshow(conf_matrix, interpolation='nearest')
        plt.title('Confusion Matrix')
        plt.colorbar()

        tick_marks = np.arange(len(self.classes))
        plt.xticks(tick_marks, self.classes, rotation=45)
        plt.yticks(tick_marks, self.classes)

        for i in range(conf_matrix.shape[0]):
            for j in range(conf_matrix.shape[1]):
                plt.text(j, i, format(conf_matrix[i, j],  'd'),
                        ha="center", va="center",
                        color="black")

        plt.ylabel('True label')
        plt.xlabel('Predicted label')
        plt.tight_layout()
        plt.show()

class CNN(FacialRecognitionAlgorithm):
    def __init__(self, modelname, dataset, epochs = 100):
        super().__init__(modelname, dataset)
        self.epochs=epochs
        
    def train(self):
        

        #train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)
        datagen = keras.preprocessing.image.ImageDataGenerator(
            rotation_range=20,
            horizontal_flip=True,
        )

        datagen.fit(self.X_train)

        self.train_data_generator = datagen.flow(self.X_train, self.y_train, batch_size=64, shuffle=True)
        self.test_data_generator = datagen.flow(self.X_test, self.y_actual, batch_size=64, shuffle=True)

        # display first image in val data batch and its label -- just for validation
        first_batch = next(self.test_data_generator)
        #display(keras.preprocessing.image.array_to_img(first_batch[0][0] * 255))
        print(first_batch[1][0])

        self.test_data_generator = datagen.flow(self.X_test, self.y_actual, batch_size=64, shuffle=True) # reset val_data_generator

        # Xception model from https://keras.io/examples/vision/image_classification_from_scratch/#using-image-data-augmentation

        # def make_model(input_shape, num_classes):
        #     inputs = keras.Input(shape=input_shape)

        #     # Entry block
        #     x = layers.Rescaling(1.0 / 255)(inputs)
        #     x = layers.Conv2D(128, 3, strides=2, padding="same")(x)
        #     x = layers.BatchNormalization()(x)
        #     x = layers.Activation("relu")(x)

        #     previous_block_activation = x  # Set aside residual

        #     for size in [256, 512, 728]:
        #         x = layers.Activation("relu")(x)
        #         x = layers.SeparableConv2D(size, 3, padding="same")(x)
        #         x = layers.BatchNormalization()(x)

        #         x = layers.Activation("relu")(x)
        #         x = layers.SeparableConv2D(size, 3, padding="same")(x)
        #         x = layers.BatchNormalization()(x)

        #         x = layers.MaxPooling2D(3, strides=2, padding="same")(x)

        #         # Project residual
        #         residual = layers.Conv2D(size, 1, strides=2, padding="same")(
        #             previous_block_activation
        #         )
        #         x = layers.add([x, residual])  # Add back residual
        #         previous_block_activation = x  # Set aside next residual

        #     x = layers.SeparableConv2D(1024, 3, padding="same")(x)
        #     x = layers.BatchNormalization()(x)
        #     x = layers.Activation("relu")(x)

        #     x = layers.GlobalAveragePooling2D()(x)
        #     if num_classes == 2:
        #         activation = "sigmoid"
        #         units = 1
        #     else:
        #         activation = "softmax"
        #         units = num_classes

        #     x = layers.Dropout(0.5)(x)
        #     outputs = layers.Dense(units, activation=activation)(x)
        #     return keras.Model(inputs, outputs)


        # model = make_model(input_shape=IMAGE_SIZE + (1, ), num_classes=len(frequencies))

        input_shape = self.dataset.images[0].shape + (1, )
        self.num_classes = len(set(self.dataset.labels))

        self.model = keras.Sequential(
            [
                keras.Input(shape=input_shape),
                layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Flatten(),
                layers.Dropout(0.5),
                layers.Dense(self.num_classes, activation="softmax"),
            ]
        )

        next(self.train_data_generator)[1].shape


        self.callbacks = [
            keras.callbacks.ModelCheckpoint("save_at_{epoch}.keras"),
        ]
        self.model.compile(
            optimizer=keras.optimizers.legacy.Adam(1e-3), # legacy for m1 support
            loss="categorical_crossentropy",
                metrics=["accuracy"],
    )
        

    def predict(self):
        self.model.fit(
            self.train_data_generator,
            epochs=self.epochs,
            callbacks=self.callbacks,
            validation_data=self.test_data_generator,
        )

    
    def show_results(self):
        y_predicted = self.model.predict(self.test_data_generator)
        
        # Convert predictions to class labels
        y_predicted = y_predicted.argmax(axis=1)
        y_predicted = np.asarray([self.dataset.labeldict[y_pred] for y_pred in y_predicted])
        print(y_predicted)
        self.y_actual = [self.dataset.labeldict[np.where(row == 1)[0][0]] for row in self.y_actual]
        print(self.y_actual)

        self.accuracy = accuracy_score(self.y_actual, y_predicted)
        print("Final Validation Accuracy: {:.2%}".format(self.accuracy))

        # Display confusion matrix
        cm = confusion_matrix(self.y_actual, y_predicted)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=self.dataset.target_names)
        disp.plot(cmap='viridis', values_format='d', xticks_rotation="vertical")

        plt.tight_layout()
        plt.show()


class LBPH(FacialRecognitionAlgorithm):
    def __init__(self, modelname, dataset,num_features, metric, radius=1):
        super().__init__(modelname,dataset)
        self.size = num_features
        self.metric = metric
        self.radius=radius

    def train(self):
        self.classes = list(set(self.y_train))
        histograms = {}
        for i, image in enumerate(self.X_train):
            histograms.setdefault(self.y_train[i], [])
            histograms[self.y_train[i]].append(self.get_Histogram(image))
        self.histograms = histograms
    
    def get_Histogram(self, grayscaled_mat): 
        lbp_mat = self.get_LBP_Mat(grayscaled_mat)
        #plt.imsave('altered_images/lbp'+name+".jpeg", lbp_mat)
        lbp_values = lbp_mat.flatten()
        histogram = np.histogram(lbp_values, bins=256, range=(0, 256))
        # if show_hist:
        #     self.show_histogram(histogram, name)
        return histogram[0]
    
    def get_LBP_Mat(self, grayscaled_mat):
        M,N=grayscaled_mat.shape
        lbp_matrix = np.zeros((M, N), dtype=np.uint8)
        for r in range(1,M-1):
            for c in range(1,N-1):
                pixel_threshold = grayscaled_mat[r][c]
               # neighbors = self.getNeighbors(grayscaled_mat,r,c)
                neighbors = self.getRNeighbors(grayscaled_mat, r, c)
                above_thresh = neighbors >= pixel_threshold
                lbp_rc = np.sum(above_thresh * (2 ** np.arange(len(neighbors))))
                lbp_matrix[r, c] = lbp_rc
        return lbp_matrix


    def distance(self,vector1, vector2, metric):
        print(vector1.shape)
        print(vector2.shape)
        if metric == "ChiSquare":
            distance = np.sum((vector1 - vector2)**2 / (vector1 + vector2 + 1e-10))

        elif metric == "EuclideanDistance":
            distance = np.linalg.norm(vector1 - vector2)

        elif metric == "NormalizedEuclideanDistance":
            distance = np.linalg.norm(vector1 - vector2) / np.linalg.norm(vector1)

        elif metric == "AbsoluteValue":
            distance = np.sum(np.abs(vector1 - vector2))

        else:
            raise ValueError("Invalid metric. Supported metrics: 'ChiSquare', 'EuclideanDistance', 'NormalizedEuclideanDistance', 'AbsoluteValue'.")

        return distance

    def getRNeighbors(self, mat, r, c):
        arr = []
        for i in range(r - self.radius, r + self.radius + 1):
            if i not in range(self.size): continue
            for j in range(c - self.radius, c + self.radius + 1):
                if j not in range(self.size): continue
                arr.append(mat[i][j])
        return np.array(arr)

    def predict(self):
        def predict1(image):
            
            myhist=self.get_Histogram(image)
            distances = []
            ppl=[]
            for person in self.histograms:
                for histogram in self.histograms[person]:
                    distances.append(self.distance(histogram,myhist,self.metric))
                    ppl.append(person)
            distances = np.array(distances)

            ind = np.argmin(distances)

            pred_label, distance= ppl[ind], distances[ind]

            return pred_label, distance
        self.accuracy = 0
        self.conf_matrix = np.zeros((len(self.dataset.labeldict), len(self.dataset.labeldict)))
        self.y_predicted=[]
        for x,y in zip(self.X_test, self.y_actual):
            
            pred = predict1(x)
            try:
                self.conf_matrix[self.dataset.reversedict[y], self.dataset.reversedict[pred[0]]] += 1
            except:
                self.conf_matrix[y, pred[0]] += 1
            self.y_predicted.append(pred[0])
            if y == pred[0]: self.accuracy += 1
    def show_results(self):
        print('accuracy', self.accuracy/len(self.X_test))
        conf_matrix = confusion_matrix(self.y_actual, np.asarray(self.y_predicted), labels=self.classes)
        
        plt.imshow(conf_matrix, interpolation='nearest')
        plt.title('Confusion Matrix')
        plt.colorbar()

        tick_marks = np.arange(len(self.classes))
        plt.xticks(tick_marks, self.classes, rotation=45)
        plt.yticks(tick_marks, self.classes)

        for i in range(conf_matrix.shape[0]):
            for j in range(conf_matrix.shape[1]):
                plt.text(j, i, format(conf_matrix[i, j],  'd'),
                        ha="center", va="center",
                        color="black")

        plt.ylabel('True label')
        plt.xlabel('Predicted label')
        plt.tight_layout()
        plt.show()


class DatasetLoader:

    #CREATED IN LOAD DATA : self.images, self.indices, self.labelnames, self.labeldict,self.reversedict, self.labels, self.target_names
    #CREATED IN SPLIT DATA: self.X_train, self.X_test, self.y_train, self.y_actual

    def load_data(self):
        # Implement the logic to load data from a specific dataset
        pass
        
    def split_data(self, prop):
        np.random.seed(18)
        np.random.shuffle(self.indices)

        cut = int((1 - prop) * len(self.images))//1

        X_train =  self.images[self.indices[:cut]]
        X_test = self.images[self.indices[cut:]]

        y_train = self.labelnames[self.indices[:cut]]
        y_actual = self.labelnames[self.indices[cut:]]
        
        return X_train, X_test, y_train, y_actual


class LFW(DatasetLoader):

    def load_data(self, minimages, maximages, modeltype, num_features=100, prop = .2):
        
        IMAGE_SIZE = num_features
        face_dataset = datasets.fetch_lfw_people(min_faces_per_person=minimages)
        self.target_names = face_dataset.target_names
        if modeltype=='Fisher':
            IMAGE_SIZE = min(IMAGE_SIZE, min(face_dataset.images[0].shape))
        if modeltype!='CNN':
            face_dataset.images = [cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE)) for image in face_dataset.images]
        
        kept_images = []
        kept_labels = []
        frequencies = {}

        for image, label in zip(face_dataset.images, face_dataset.target):
            if label not in frequencies:
                frequencies[label] = 0
            if frequencies[label] > maximages:
                continue
            kept_images.append(image)
            kept_labels.append(label)
            frequencies[label] += 1

        if modeltype!='CNN':
            kept_images = np.array([vector.reshape((IMAGE_SIZE, IMAGE_SIZE)) for vector in kept_images])
        self.labels = np.asarray(kept_labels)

        self.labeldict = {i: name for i, name in enumerate(face_dataset.target_names)}
        self.reversedict = {name: i for i, name in enumerate(face_dataset.target_names)}
        labelnames = []
        for i in range(len(self.labels)):
            labelnames.append(self.labeldict[self.labels[i]])

        self.labelnames = np.asarray(labelnames)

        self.indices = np.arange(len(kept_images))
        self.images=np.asarray(kept_images)
        
        if modeltype=="CNN":
            images = np.expand_dims(np.asarray(kept_images), axis=-1) # necessary to show there is 1 channel (grayscale)?
            labels = keras.utils.to_categorical(np.asarray(kept_labels))
            self.X_train, self.X_test, self.y_train, self.y_actual = train_test_split(images, labels, test_size=prop, random_state=18)
       
        else:
            self.X_train, self.X_test, self.y_train, self.y_actual = self.split_data()


    def split_data(self, prop=.2):
        return super().split_data(prop)

class MLApp(QWidget):
    def __init__(self):
        super().__init__()
        self.init_ui()

    def init_ui(self):
        self.setWindowTitle('ML Algorithm Selector')
        self.setGeometry(100, 100, 600, 300)

        algolabel = QLabel('Select your ML algorithm:')
        self.algorithm_combo = QComboBox()
        self.algorithm_combo.addItems(['', 'Eigenfaces', 'Fisherfaces', 'LBPH', 'CNN'])
        self.algorithm_combo.currentIndexChanged.connect(self.update_hyperparameters)

        datalabel = QLabel('Select your Dataset:')
        self.dataset_combo = QComboBox()
        self.dataset_combo.addItems(['', 'LFW', 'Not Ready. Dont Pick Me'])

        self.hyperparam_layout = QFormLayout()

        self.num_features_widget = QLineEdit(str(150))
        self.train_test_split_widget = QLineEdit(str(0.8))
        self.min_images_widget = QLineEdit(str(50))
        self.max_images_widget = QLineEdit(str(150))
        self.c_widget = QLineEdit(str(1.0))
        self.metric_widget = QLineEdit("ChiSquare")
        self.epochs_widget = QLineEdit(str(75))

        train_test_button = QPushButton('Train/Test Algorithm')
        train_test_button.clicked.connect(self.train_test_algorithm)

        layout = QVBoxLayout()
        layout.addWidget(algolabel)
        layout.addWidget(self.algorithm_combo)
        layout.addWidget(datalabel)
        layout.addWidget(self.dataset_combo)
        layout.addLayout(self.hyperparam_layout)
        layout.addWidget(train_test_button)

        self.setLayout(layout)
        self.show()

    def update_hyperparameters(self):
        self.clear_hyperparam_layout()

        modeltype = self.algorithm_combo.currentText()

        # Common hyperparameters for all algorithms
        self.add_hyperparam_widget("Number of Features:", self.num_features_widget)
        self.add_hyperparam_widget("Train/Test Split Proportion:", self.train_test_split_widget)
        self.add_hyperparam_widget("Min Images:", self.min_images_widget)
        self.add_hyperparam_widget("Max Images:", self.max_images_widget)

        if modeltype == 'Eigenfaces':
            self.add_hyperparam_widget("C:", self.c_widget)
        elif modeltype == 'Fisherfaces':
            pass  # No additional hyperparameters for Fisherfaces
        elif modeltype == 'LBPH':
            self.add_hyperparam_widget("Metric:", self.metric_widget)
        elif modeltype == 'CNN':
            self.add_hyperparam_widget("Epochs:", self.epochs_widget)

    def add_hyperparam_widget(self, label_text, widget):
        label = QLabel(label_text)
        self.hyperparam_layout.addRow(label, widget)

    def clear_hyperparam_layout(self):
        while self.hyperparam_layout.count() > 0:
            item = self.hyperparam_layout.takeAt(0)
            widget = item.widget()
            if widget is not None:
                widget.deleteLater()

    def train_test_algorithm(self):
        datasettype = self.dataset_combo.currentText()
        modeltype = self.algorithm_combo.currentText()
        num_features = int(self.num_features_widget.text())
        train_test_split = float(self.train_test_split_widget.text())
        min_images = int(self.min_images_widget.text())
        max_images = int(self.max_images_widget.text())

        
        if modeltype == 'Eigenfaces':
            print("Running Eigenfaces")
            c_value = float(self.c_widget.text())
            if datasettype == "LFW":
                dataset = LFW()
                dataset.load_data(min_images, max_images, modeltype, num_features=num_features, prop=1 - train_test_split)
            f = Eigenfaces(modeltype, dataset, num_features,c_value=1)
        elif modeltype == 'Fisherfaces':
            print("Running Fisherfaces")
            if datasettype == "LFW":
                dataset = LFW()
                dataset.load_data(min_images, max_images, modeltype, num_features=num_features, prop=1 - train_test_split)
            f = FisherFaces(modeltype, dataset, num_features)
        elif modeltype == 'LBPH':
            print("Running LBPH")
            metric = self.metric_widget.text()
            if datasettype == "LFW":
                dataset = LFW()
                dataset.load_data(min_images, max_images, modeltype, num_features=num_features, prop=1 - train_test_split)
            f = LBPH(modeltype, dataset, num_features, metric)
        elif modeltype == 'CNN':
            print("RUNNING CNN")
            epochs = int(self.epochs_widget.text())
            if datasettype == "LFW":
                dataset = LFW()
                dataset.load_data(min_images, max_images, modeltype, num_features=num_features, prop=1 - train_test_split)
            f = CNN(modeltype, dataset, epochs)

        # Print all hyperparameter values and the dataset being used on separate lines
        print(f"Number of Features: {num_features}")
        print(f"Train/Test Split Proportion: {train_test_split}")
        print(f"Min Images: {min_images}")
        print(f"Max Images: {max_images}")
        print(f"Dataset being used: {datasettype}")
        if modeltype == 'Eigenfaces':
            print(f"C Value: {c_value}")
        if modeltype == "LBPH":
            print(f"Distance Metric: {metric}")
        if modeltype == "CNN":
            print(f"# of Epochs: {epochs}")

        print(3)
        f.X_train, f.X_test, f.y_train, f.y_actual = f.dataset.X_train, f.dataset.X_test, f.dataset.y_train, f.dataset.y_actual
        f.train()
        f.predict()
        f.show_results()
if __name__ == '__main__':
 
    app = QApplication(sys.argv)
    ml_app = MLApp()
    ml_app.show()
    sys.exit(app.exec_())

